{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Ironhack logo](https://i.imgur.com/1QgrNNw.png)\n",
    "\n",
    "# Challenge 1: Natural Language Process Overview\n",
    "\n",
    "In this challenge, we will present an overview of Natural Language Processing, or NLP. You will watch two videos to have a general understanding about NLP.\n",
    "\n",
    "**Suggested time on this challenge: 30 min**\n",
    "\n",
    "## Objectives\n",
    "\n",
    "* Understand what is NLP.\n",
    "* Learn about the general evolution of NLP technology.\n",
    "* Learn about the common areas of research in NLP.\n",
    "* Learn about the common applications of NLP.\n",
    "* Understand the general steps to conduct NLP analysis.\n",
    "* Install NLTK.\n",
    "\n",
    "## Install NLTK\n",
    "\n",
    "Before we start learning, let's first install [Python NLTK](https://www.nltk.org/) because it takes a while to download the package. Follow the steps below.\n",
    "\n",
    "1. **Install NLTK:** \n",
    "\n",
    "\tIf you have installed `pip` on your computer, simply run `pip install nltk`. If you don't have `pip`, follow the instructions [here](https://www.nltk.org/install.html).\n",
    "\n",
    "1. **Install NLTK data:** \n",
    "\n",
    "\tLaunch Python shell and execute\n",
    "\n",
    "\t```python\n",
    "\t>>> import nltk\n",
    "\t>>> nltd.download()\n",
    "\t```\n",
    "\n",
    "The data library is over 3gb and take a while to download. You can view the downloading progress in the download manager that is automatically opened by NLTK. While the data are being downloaded, proceed to the next section.\n",
    "\n",
    "For more information about downloading NLTK data, refer to [here](https://www.nltk.org/data.html).\n",
    "\n",
    "## Video 1: [Natural Language Processing Crash Course](https://www.youtube.com/watch?v=fOvTtapxa9c)\n",
    "\n",
    "[![Natural Language Processing: Crash Course](crash-course.jpg)](https://www.youtube.com/watch?v=fOvTtapxa9c)\n",
    "\n",
    "### Key Knowledge Points\n",
    "\n",
    "* Computer language vs natural (human) language: how they differ?\n",
    "* Why NLP needs to deconstruct the natural language in order to analyze?\n",
    "* What is the biggest problem for computer to understand natural language?\n",
    "* What is a *parse tree*?\n",
    "* How are the first-generation NLP algorithms (based on semantic rules) different from modern NLP algorithms (based on knowledge graphs and machine learning)?\n",
    "* How did early-generation chatbots (e.g. Eliza) recognize natual languge? What are the limitations?\n",
    "* How do modern chatbots (e.g. [IBM Watson](https://www.ibm.com/watson/how-to-build-a-chatbot/), [Facebook Messenger Chatbot](https://developers.facebook.com/docs/messenger-platform/built-in-nlp/)) recognize natural language?\n",
    "* What is speech recognition? What is its relation to NLP?\n",
    "* How does speech recognition work (how do computers translate sounds into texts)?\n",
    "* What is speech synthesis?\n",
    "* What are essential for NLP algorithms to produce more accurate results?\n",
    "\n",
    "## Video 2: [Natural Language Processing In 10 Minutes](https://www.youtube.com/watch?v=5ctbvkAMQO4)\n",
    "\n",
    "[![Natural Language Processing In 10 Minutes](nlp-10-min.jpg)](https://www.youtube.com/watch?v=5ctbvkAMQO4)\n",
    "\n",
    "### Key Knowledge Points\n",
    "\n",
    "* What is text mining / text analysis?\n",
    "* What is sentiment analysis?\n",
    "* What are the common areas of application of NLP?\n",
    "* What are the 6 general steps of NLP analysis?\n",
    "* What is *tokenization*?\n",
    "* What is *stemming*?\n",
    "* What is *lemmatization*? How is lemmatization different from stemming?\n",
    "* What are *POS tags*?\n",
    "* What does *named entity recognition* do?\n",
    "* What does *trunking* do?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/javier/snap/jupyter/common/lib/python3.7/site-packages (3.4.5)\n",
      "Requirement already satisfied: six in /snap/jupyter/6/lib/python3.7/site-packages (from nltk) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /home/javier/snap/jupyter/6/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/javier/snap/jupyter/6/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/javier/snap/jupyter/6/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#import ssl\n",
    "\n",
    "#try:\n",
    " #   _create_unverified_https_context = ssl._create_unverified_context\n",
    "#except AttributeError:\n",
    " #   pass\n",
    "#else:\n",
    " #   ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test NLTK Installation\n",
    "\n",
    "Now your NLTK data library should have finished downloading. Confirm that in the download manager. Launch Python shell and test the installation:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "brown.words()[0:10]\n",
    "\n",
    "\n",
    "brown.tagged_words()[0:10]\n",
    "\n",
    "\n",
    "text = 'Ironhack is a Global Tech School ranked num 2 worldwide.  ",
    " ",
    "Our mission is to help people transform their careers and join a thriving community of tech professionals that love what they do. This ideology is reflected in our teaching practices, which consist of a nine-weeks immersive programming, UX/UI design or Data Analytics course as well as a one-week hiring fair aimed at helping our students change their career and get a job straight after the course. We are present in 8 countries and have campuses in 9 locations - Madrid, Barcelona, Miami, Paris, Mexico City,  Berlin, Amsterdam, Sao Paulo and Lisbon.'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ironhack',\n",
       " 'is',\n",
       " 'a',\n",
       " 'Global',\n",
       " 'Tech',\n",
       " 'School',\n",
       " 'ranked',\n",
       " 'num',\n",
       " '2',\n",
       " 'worldwide',\n",
       " '.',\n",
       " 'Our',\n",
       " 'mission',\n",
       " 'is',\n",
       " 'to',\n",
       " 'help',\n",
       " 'people',\n",
       " 'transform',\n",
       " 'their',\n",
       " 'careers',\n",
       " 'and',\n",
       " 'join',\n",
       " 'a',\n",
       " 'thriving',\n",
       " 'community',\n",
       " 'of',\n",
       " 'tech',\n",
       " 'professionals',\n",
       " 'that',\n",
       " 'love',\n",
       " 'what',\n",
       " 'they',\n",
       " 'do',\n",
       " '.',\n",
       " 'This',\n",
       " 'ideology',\n",
       " 'is',\n",
       " 'reflected',\n",
       " 'in',\n",
       " 'our',\n",
       " 'teaching',\n",
       " 'practices',\n",
       " ',',\n",
       " 'which',\n",
       " 'consist',\n",
       " 'of',\n",
       " 'a',\n",
       " 'nine-weeks',\n",
       " 'immersive',\n",
       " 'programming',\n",
       " ',',\n",
       " 'UX/UI',\n",
       " 'design',\n",
       " 'or',\n",
       " 'Data',\n",
       " 'Analytics',\n",
       " 'course',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'a',\n",
       " 'one-week',\n",
       " 'hiring',\n",
       " 'fair',\n",
       " 'aimed',\n",
       " 'at',\n",
       " 'helping',\n",
       " 'our',\n",
       " 'students',\n",
       " 'change',\n",
       " 'their',\n",
       " 'career',\n",
       " 'and',\n",
       " 'get',\n",
       " 'a',\n",
       " 'job',\n",
       " 'straight',\n",
       " 'after',\n",
       " 'the',\n",
       " 'course',\n",
       " '.',\n",
       " 'We',\n",
       " 'are',\n",
       " 'present',\n",
       " 'in',\n",
       " '8',\n",
       " 'countries',\n",
       " 'and',\n",
       " 'have',\n",
       " 'campuses',\n",
       " 'in',\n",
       " '9',\n",
       " 'locations',\n",
       " '-',\n",
       " 'Madrid',\n",
       " ',',\n",
       " 'Barcelona',\n",
       " ',',\n",
       " 'Miami',\n",
       " ',',\n",
       " 'Paris',\n",
       " ',',\n",
       " 'Mexico',\n",
       " 'City',\n",
       " ',',\n",
       " 'Berlin',\n",
       " ',',\n",
       " 'Amsterdam',\n",
       " ',',\n",
       " 'Sao',\n",
       " 'Paulo',\n",
       " 'and',\n",
       " 'Lisbon',\n",
       " '.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import sent_tokenize, word_tokenize\n",
    "\n",
    "sent_tokenize(text)\n",
    "\n",
    "\n",
    "\n",
    "word_tokenize(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see the above outputs and have no errors, you've successfully installed NLTK and NLTK data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
